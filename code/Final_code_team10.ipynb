{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de386d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24e65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/MBTI_train.csv', header=None, encoding = 'ISO 8859-1')\n",
    "test_data = pd.read_csv('./data/MBTI_test.csv', header =None,encoding = 'ISO 8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478aab8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTP</td>\n",
       "      <td>say process model list like subscriber channel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>upon much manipulate retail finish like sacrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>fit yes certain bff social feel goal go know n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>complete love within someone ideal joke solvea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>public strictly thing person x question person...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0  INTP  say process model list like subscriber channel...\n",
       "1  INFJ  upon much manipulate retail finish like sacrif...\n",
       "2  INFJ  fit yes certain bff social feel goal go know n...\n",
       "3  INTJ  complete love within someone ideal joke solvea...\n",
       "4  ENTJ  public strictly thing person x question person..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e969a63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INTP', 'INFJ', 'INTJ', 'ENTJ', 'ENTP', 'INFP', 'ISTP', 'ISFJ',\n",
       "       'ENFP', 'ISFP', 'ISTJ', 'ENFJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[:,0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a64004",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTP_table = train_data[train_data.iloc[:,0] == 'INTP'] # 1\n",
    "INFJ_table = train_data[train_data.iloc[:,0] == 'INFJ'] # 2\n",
    "INTJ_table = train_data[train_data.iloc[:,0] == 'INTJ'] # 3\n",
    "ENTJ_table = train_data[train_data.iloc[:,0] == 'ENTJ'] # 4\n",
    "ENTP_table = train_data[train_data.iloc[:,0] == 'ENTP'] # 5\n",
    "INFP_table = train_data[train_data.iloc[:,0] == 'INFP'] # 6 \n",
    "ISTP_table = train_data[train_data.iloc[:,0] == 'ISTP'] # 7\n",
    "ISFJ_table = train_data[train_data.iloc[:,0] == 'ISFJ'] # 8\n",
    "ENFP_table = train_data[train_data.iloc[:,0] == 'ENFP'] # 9\n",
    "ISFP_table = train_data[train_data.iloc[:,0] == 'ISFP'] # 10 \n",
    "ISTJ_table = train_data[train_data.iloc[:,0] == 'ISTJ'] # 11\n",
    "ENFJ_table = train_data[train_data.iloc[:,0] == 'ENFJ'] # 12\n",
    "ESTP_table = train_data[train_data.iloc[:,0] == 'ESTP'] # 13\n",
    "ESFP_table = train_data[train_data.iloc[:,0] == 'ESFP'] # 14\n",
    "ESTJ_table = train_data[train_data.iloc[:,0] == 'ESTJ'] # 15\n",
    "ESFJ_table = train_data[train_data.iloc[:,0] == 'ESFJ'] # 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857abfbd",
   "metadata": {},
   "source": [
    "**1.mbti별 단어 빈도수 계산**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79b2e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17690\n"
     ]
    }
   ],
   "source": [
    "# INTP(1)\n",
    "print(INTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INTP_table.shape[0]):\n",
    "    text = INTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list)) # 각 data별로 단어 개수 counting\n",
    "\n",
    "# word count\n",
    "intp = collections.Counter()\n",
    "for i in tmp:\n",
    "    intp += i # mbti별로 단어 개수 counting\n",
    "    \n",
    "# save dataframe\n",
    "intp_df = pd.DataFrame.from_dict(intp, orient = 'index').reset_index()\n",
    "#intp_df.to_csv('./mbti_table/intp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a762c099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say</td>\n",
       "      <td>46415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process</td>\n",
       "      <td>5339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>list</td>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "      <td>88915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subscriber</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>channel</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>region</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>act</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>position</td>\n",
       "      <td>2272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index      0\n",
       "0         say  46415\n",
       "1     process   5339\n",
       "2       model   2464\n",
       "3        list   2989\n",
       "4        like  88915\n",
       "5  subscriber     95\n",
       "6     channel    567\n",
       "7      region    212\n",
       "8         act   5320\n",
       "9    position   2272"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4bac151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10765\n"
     ]
    }
   ],
   "source": [
    "# INFJ(2)\n",
    "print(INFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INFJ_table.shape[0]):\n",
    "    text = INFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "infj = collections.Counter()\n",
    "for i in tmp:\n",
    "    infj += i\n",
    "    \n",
    "# save dataframe\n",
    "infj_df = pd.DataFrame.from_dict(infj, orient = 'index').reset_index()\n",
    "#infj_df.to_csv('./mbti_table/infj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28453189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16079\n"
     ]
    }
   ],
   "source": [
    "# INTJ(3)\n",
    "print(INTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INTJ_table.shape[0]):\n",
    "    text = INTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "intj = collections.Counter()\n",
    "for i in tmp:\n",
    "    intj += i\n",
    "    \n",
    "# save dataframe\n",
    "intj_df = pd.DataFrame.from_dict(intj, orient = 'index').reset_index()\n",
    "#intj_df.to_csv('./mbti_table/intj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd3542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2106\n"
     ]
    }
   ],
   "source": [
    "# ENTJ(4)\n",
    "print(ENTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENTJ_table.shape[0]):\n",
    "    text = ENTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "entj = collections.Counter()\n",
    "for i in tmp:\n",
    "    entj += i\n",
    "    \n",
    "# save dataframe\n",
    "entj_df = pd.DataFrame.from_dict(entj, orient = 'index').reset_index()\n",
    "#entj_df.to_csv('./mbti_table/entj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae23b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8303\n"
     ]
    }
   ],
   "source": [
    "# ENTP(5)\n",
    "print(ENTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENTP_table.shape[0]):\n",
    "    text = ENTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "entp = collections.Counter()\n",
    "for i in tmp:\n",
    "    entp += i\n",
    "    \n",
    "# save dataframe\n",
    "entp_df = pd.DataFrame.from_dict(entp, orient = 'index').reset_index()\n",
    "#entp_df.to_csv('./mbti_table/entp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a525e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8444\n"
     ]
    }
   ],
   "source": [
    "# INFP(6)\n",
    "print(INFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INFP_table.shape[0]):\n",
    "    text = INFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "infp = collections.Counter()\n",
    "for i in tmp:\n",
    "    infp += i\n",
    "    \n",
    "# save dataframe\n",
    "infp_df = pd.DataFrame.from_dict(infp, orient = 'index').reset_index()\n",
    "#infp_df.to_csv('./mbti_table/infp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4175c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2394\n"
     ]
    }
   ],
   "source": [
    "# ISTP(7)\n",
    "print(ISTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISTP_table.shape[0]):\n",
    "    text = ISTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "istp = collections.Counter()\n",
    "for i in tmp:\n",
    "    istp += i\n",
    "    \n",
    "# save dataframe\n",
    "istp_df = pd.DataFrame.from_dict(istp, orient = 'index').reset_index()\n",
    "#istp_df.to_csv('./mbti_table/istp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d1ca205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n"
     ]
    }
   ],
   "source": [
    "# ISFJ(8)\n",
    "print(ISFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISFJ_table.shape[0]):\n",
    "    text = ISFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "isfj = collections.Counter()\n",
    "for i in tmp:\n",
    "    isfj += i\n",
    "    \n",
    "# save dataframe\n",
    "isfj_df = pd.DataFrame.from_dict(isfj, orient = 'index').reset_index()\n",
    "#isfj_df.to_csv('./mbti_table/isfj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52a2986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4338\n"
     ]
    }
   ],
   "source": [
    "# ENFP(9)\n",
    "print(ENFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENFP_table.shape[0]):\n",
    "    text = ENFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "enfp = collections.Counter()\n",
    "for i in tmp:\n",
    "    enfp += i\n",
    "    \n",
    "# save dataframe\n",
    "enfp_df = pd.DataFrame.from_dict(enfp, orient = 'index').reset_index()\n",
    "#enfp_df.to_csv('./mbti_table/enfp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93864879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620\n"
     ]
    }
   ],
   "source": [
    "# ISFP(10)\n",
    "print(ISFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISFP_table.shape[0]):\n",
    "    text = ISFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "isfp = collections.Counter()\n",
    "for i in tmp:\n",
    "    isfp += i\n",
    "    \n",
    "# save dataframe\n",
    "isfp_df = pd.DataFrame.from_dict(isfp, orient = 'index').reset_index()\n",
    "#isfp_df.to_csv('./mbti_table/isfp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878\n"
     ]
    }
   ],
   "source": [
    "# ISTJ(11)\n",
    "print(ISTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISTJ_table.shape[0]):\n",
    "    text = ISTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "istj = collections.Counter()\n",
    "for i in tmp:\n",
    "    istj += i\n",
    "    \n",
    "# save dataframe\n",
    "istj_df = pd.DataFrame.from_dict(istj, orient = 'index').reset_index()\n",
    "#istj_df.to_csv('./mbti_table/istj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75575ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "# ENFJ(12)\n",
    "print(ENFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENFJ_table.shape[0]):\n",
    "    text = ENFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "enfj = collections.Counter()\n",
    "for i in tmp:\n",
    "    enfj += i\n",
    "    \n",
    "# save dataframe\n",
    "enfj_df = pd.DataFrame.from_dict(enfj, orient = 'index').reset_index()\n",
    "#enfj_df.to_csv('./mbti_table/enfj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be719533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814\n"
     ]
    }
   ],
   "source": [
    "# ESTP(13)\n",
    "print(ESTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESTP_table.shape[0]):\n",
    "    text = ESTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "estp = collections.Counter()\n",
    "for i in tmp:\n",
    "    estp += i\n",
    "    \n",
    "# save dataframe\n",
    "estp_df = pd.DataFrame.from_dict(estp, orient = 'index').reset_index()\n",
    "#estp_df.to_csv('./mbti_table/estp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3ed6309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n"
     ]
    }
   ],
   "source": [
    "# ESFP(14)\n",
    "print(ESFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESFP_table.shape[0]):\n",
    "    text = ESFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "esfp = collections.Counter()\n",
    "for i in tmp:\n",
    "    esfp += i\n",
    "    \n",
    "# save dataframe\n",
    "esfp_df = pd.DataFrame.from_dict(esfp, orient = 'index').reset_index()\n",
    "#esfp_df.to_csv('./mbti_table/esfp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7695810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "# ESTJ(15)\n",
    "print(ESTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESTJ_table.shape[0]):\n",
    "    text = ESTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "estj = collections.Counter()\n",
    "for i in tmp:\n",
    "    estj += i\n",
    "    \n",
    "# save dataframe\n",
    "estj_df = pd.DataFrame.from_dict(estj, orient = 'index').reset_index()\n",
    "#estj_df.to_csv('./mbti_table/estj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce71d9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "# ESFJ(16)\n",
    "print(ESFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESFJ_table.shape[0]):\n",
    "    text = ESFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "esfj = collections.Counter()\n",
    "for i in tmp:\n",
    "    esfj += i\n",
    "    \n",
    "# save dataframe\n",
    "esfj_df = pd.DataFrame.from_dict(esfj, orient = 'index').reset_index()\n",
    "#esfj_df.to_csv('./mbti_table/esfj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc9214e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intp_df = pd.read_csv('./mbti_table/intp_df.csv') # 1\n",
    "#infj_df = pd.read_csv('./mbti_table/infj_df.csv') # 2\n",
    "#intj_df = pd.read_csv('./mbti_table/intj_df.csv') # 3\n",
    "#entj_df = pd.read_csv('./mbti_table/entj_df.csv') # 4\n",
    "#entp_df = pd.read_csv('./mbti_table/entp_df.csv') # 5\n",
    "#infp_df = pd.read_csv('./mbti_table/infp_df.csv') # 6\n",
    "#istp_df = pd.read_csv('./mbti_table/istp_df.csv') # 7\n",
    "#isfj_df = pd.read_csv('./mbti_table/isfj_df.csv') # 8\n",
    "#enfp_df = pd.read_csv('./mbti_table/enfp_df.csv') # 9\n",
    "#isfp_df = pd.read_csv('./mbti_table/isfp_df.csv') # 10\n",
    "#istj_df = pd.read_csv('./mbti_table/istj_df.csv') # 11\n",
    "#enfj_df = pd.read_csv('./mbti_table/enfj_df.csv') # 12\n",
    "#estp_df = pd.read_csv('./mbti_table/estp_df.csv') # 13\n",
    "#esfp_df = pd.read_csv('./mbti_table/esfp_df.csv') # 14\n",
    "#estj_df = pd.read_csv('./mbti_table/estj_df.csv') # 15\n",
    "#esfj_df = pd.read_csv('./mbti_table/esfj_df.csv') # 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca566e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867782ac",
   "metadata": {},
   "source": [
    "**2. 빈도수를 기반으로 단어 샘플링**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "312382ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_list = ['intp', 'infj', 'intj', 'entj', 'entp', 'infp', 'istp', 'isfj',\n",
    "             'enfp', 'isfp', 'istj', 'enfj', 'estp', 'esfp', 'estj', 'esfj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc14290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_preq = pd.DataFrame(train_data.iloc[:,0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "685dc101",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f87f2bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8845\n",
      "8845\n"
     ]
    }
   ],
   "source": [
    "# intp (1)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = intp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INTP'].item()/ratio) * 400\n",
    "\n",
    "sample = intp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq) # 단어 샘플링\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) + \" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "intp_new_data = pd.DataFrame({'y':'INTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44f7d9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTP</td>\n",
       "      <td>clothe ven peace simply function function thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTP</td>\n",
       "      <td>back poetry currently history actually divide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>anyway still depend least seem night monologue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTP</td>\n",
       "      <td>serious hear since one completely metal engage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTP</td>\n",
       "      <td>try one much date take bite take hello feel pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTP</td>\n",
       "      <td>let view fuckload level basically within apart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>INTP</td>\n",
       "      <td>love would fit thing father least te people cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTP</td>\n",
       "      <td>honestly couch rigid fraud black mph twenty u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INTP</td>\n",
       "      <td>claim day great chore influence phrase duty fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INTP</td>\n",
       "      <td>something resu either good people world sugges...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y                                                  x\n",
       "0  INTP  clothe ven peace simply function function thin...\n",
       "1  INTP  back poetry currently history actually divide ...\n",
       "2  INTP  anyway still depend least seem night monologue...\n",
       "3  INTP  serious hear since one completely metal engage...\n",
       "4  INTP  try one much date take bite take hello feel pa...\n",
       "5  INTP  let view fuckload level basically within apart...\n",
       "6  INTP  love would fit thing father least te people cr...\n",
       "7  INTP  honestly couch rigid fraud black mph twenty u ...\n",
       "8  INTP  claim day great chore influence phrase duty fr...\n",
       "9  INTP  something resu either good people world sugges..."
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intp_new_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "675507f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5382\n",
      "5382\n"
     ]
    }
   ],
   "source": [
    "# infj (2)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = infj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = infj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "infj_new_data = pd.DataFrame({'y':'INFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d50786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8039\n",
      "8039\n"
     ]
    }
   ],
   "source": [
    "# intj (3)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = intj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = intj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "intj_new_data = pd.DataFrame({'y':'INTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80ef0cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053\n",
      "1053\n"
     ]
    }
   ],
   "source": [
    "# entj (4)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = entj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = entj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "entj_new_data = pd.DataFrame({'y':'ENTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f8be706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4151\n",
      "4151\n"
     ]
    }
   ],
   "source": [
    "# entp (5)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = entp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENTP'].item()/ratio) * 400\n",
    "\n",
    "sample = entp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "entp_new_data = pd.DataFrame({'y':'ENTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd3d580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4222\n",
      "4222\n"
     ]
    }
   ],
   "source": [
    "# infp (6)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = infp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INFP'].item()/ratio) * 400\n",
    "\n",
    "sample = infp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "infp_new_data = pd.DataFrame({'y':'INFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c7ad85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1197\n",
      "1197\n"
     ]
    }
   ],
   "source": [
    "# istp (7)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = istp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISTP'].item()/ratio) * 400\n",
    "\n",
    "sample = istp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "istp_new_data = pd.DataFrame({'y':'ISTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "858c6b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "# isfj (8)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = isfj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = isfj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "isfj_new_data = pd.DataFrame({'y':'ISFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff5c1a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169\n",
      "2169\n"
     ]
    }
   ],
   "source": [
    "# enfp (9)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = enfp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENFP'].item()/ratio) * 400\n",
    "\n",
    "sample = enfp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "enfp_new_data = pd.DataFrame({'y':'ENFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d80c3c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "# isfp (10)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = isfp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISFP'].item()/ratio) * 400\n",
    "\n",
    "sample = isfp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "isfp_new_data = pd.DataFrame({'y':'ISFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5375e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439\n",
      "439\n"
     ]
    }
   ],
   "source": [
    "# istj (11)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = istj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = istj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "istj_new_data = pd.DataFrame({'y':'ISTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00e3608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "# enfj (12)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = enfj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = enfj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "enfj_new_data = pd.DataFrame({'y':'ENFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "598cc53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n",
      "407\n"
     ]
    }
   ],
   "source": [
    "# estp (13)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = estp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESTP'].item()/ratio) * 400\n",
    "\n",
    "sample = estp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "estp_new_data = pd.DataFrame({'y':'ESTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "751cbe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "# esfp (14)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = esfp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESFP'].item()/ratio) * 400\n",
    "\n",
    "sample = esfp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "esfp_new_data = pd.DataFrame({'y':'ESFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aeb271b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# estj (15)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = estj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = estj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "estj_new_data = pd.DataFrame({'y':'ESTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dc00ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "# esfj (16)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = esfj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = esfj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "esfj_new_data = pd.DataFrame({'y':'ESFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e8f5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = pd.concat([intp_new_data, infj_new_data, intj_new_data, entj_new_data,\n",
    "                            entp_new_data, infp_new_data, istp_new_data, isfj_new_data,\n",
    "                            enfp_new_data, isfp_new_data, istj_new_data, enfj_new_data,\n",
    "                            estp_new_data, esfp_new_data, estj_new_data, esfj_new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cb71eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = ['y', 'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07ebd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_new_train_data = pd.concat([train_data, new_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1350b6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111533, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_new_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "183d2bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTP</td>\n",
       "      <td>say process model list like subscriber channel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>upon much manipulate retail finish like sacrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>fit yes certain bff social feel goal go know n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>complete love within someone ideal joke solvea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>public strictly thing person x question person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>generation rotation list boyfriend people disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>natural something top define without seem towa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>think people hard ni also usually look every t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>see freak drive approach idiot teacher great m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ESFJ</td>\n",
       "      <td>v top workable others calm comment well expres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111533 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y                                                  x\n",
       "0   INTP  say process model list like subscriber channel...\n",
       "1   INFJ  upon much manipulate retail finish like sacrif...\n",
       "2   INFJ  fit yes certain bff social feel goal go know n...\n",
       "3   INTJ  complete love within someone ideal joke solvea...\n",
       "4   ENTJ  public strictly thing person x question person...\n",
       "..   ...                                                ...\n",
       "54  ESFJ  generation rotation list boyfriend people disc...\n",
       "55  ESFJ  natural something top define without seem towa...\n",
       "56  ESFJ  think people hard ni also usually look every t...\n",
       "57  ESFJ  see freak drive approach idiot teacher great m...\n",
       "58  ESFJ  v top workable others calm comment well expres...\n",
       "\n",
       "[111533 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_new_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b456b",
   "metadata": {},
   "source": [
    "**modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1d708b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_accuracy(prediction, answer):\n",
    "    prediction_list = list(prediction)\n",
    "    answer_list = list(answer)\n",
    "    list_size = answer.size\n",
    "    \n",
    "    correct_num = 0\n",
    "    \n",
    "    for i in range(list_size):\n",
    "        for j in range(4):\n",
    "            if prediction_list[i][j] == answer_list[i][j] :\n",
    "                correct_num += 1;\n",
    "                \n",
    "    accuracy = correct_num / (4*list_size)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0277e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = total_new_train_data.iloc[:,1] # features\n",
    "new_y = total_new_train_data.iloc[:,0]  # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6018a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     say process model list like subscriber channel...\n",
       "1     upon much manipulate retail finish like sacrif...\n",
       "2     fit yes certain bff social feel goal go know n...\n",
       "3     complete love within someone ideal joke solvea...\n",
       "4     public strictly thing person x question person...\n",
       "                            ...                        \n",
       "54    generation rotation list boyfriend people disc...\n",
       "55    natural something top define without seem towa...\n",
       "56    think people hard ni also usually look every t...\n",
       "57    see freak drive approach idiot teacher great m...\n",
       "58    v top workable others calm comment well expres...\n",
       "Name: x, Length: 111533, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "079dde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#vectorizer = TfidfVectorizer(min_df = 4, sublinear_tf = True, ngram_range = (1, 2))\n",
    "vectorizer = TfidfVectorizer()\n",
    "   \n",
    "# Training the vectorizer:\n",
    "X_train_tfidf = vectorizer.fit_transform(new_X)\n",
    "X_test_tfidf = vectorizer.transform(test_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1383b",
   "metadata": {},
   "source": [
    "**linearSVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "77a5e847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_model = LinearSVC()\n",
    "svc_model.fit(X_train_tfidf, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f8e54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_train_predict = svc_model.predict(X_train_tfidf)\n",
    "svc_test_predict = svc_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "462cb142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련데이터 전체 단위 정확도:  0.9817811768714192\n"
     ]
    }
   ],
   "source": [
    "print('훈련데이터 전체 단위 정확도: ', np.mean(svc_train_predict == new_y)) # 0.9817811768714192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19a81418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 후 훈련데이터 글자별 정확도:  0.9933741583208557\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 후 훈련데이터 글자별 정확도: ', caculate_accuracy(svc_train_predict, new_y)) # 0.9933741583208557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4a0f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svc_test_predict).to_csv('Final_result_team10.csv', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff6a37df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INTP', 'INFJ', 'INFJ', ..., 'ESFJ', 'ESFJ', 'ESFJ'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "762c27cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENFP', 'ENTP', 'INTJ', ..., 'INTP', 'ENTJ', 'INFP'], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d37e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
