{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de386d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24e65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/MBTI_train.csv', header=None, encoding = 'ISO 8859-1')\n",
    "test_data = pd.read_csv('./data/MBTI_test.csv', header =None,encoding = 'ISO 8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478aab8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTP</td>\n",
       "      <td>say process model list like subscriber channel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>upon much manipulate retail finish like sacrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>fit yes certain bff social feel goal go know n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>complete love within someone ideal joke solvea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>public strictly thing person x question person...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0  INTP  say process model list like subscriber channel...\n",
       "1  INFJ  upon much manipulate retail finish like sacrif...\n",
       "2  INFJ  fit yes certain bff social feel goal go know n...\n",
       "3  INTJ  complete love within someone ideal joke solvea...\n",
       "4  ENTJ  public strictly thing person x question person..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7defa968",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.iloc[:,1] # features\n",
    "y = train_data.iloc[:,0]  # labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2178d05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48796    perceiver knight phase cheat xsfp social much ...\n",
       "1743     burn tighten enough capitalism tough together ...\n",
       "13297    farmer back various around play fact minecraft...\n",
       "48956    prone plan back thus end hey weekend hope odd ...\n",
       "21771    comrade thank really instead time r routine de...\n",
       "                               ...                        \n",
       "37194    behavior use especially mind jump girl type th...\n",
       "6265     see si bore different part dominant isfj show ...\n",
       "54886    instead write think would suspect sound emotio...\n",
       "860      attempt bother useful put craigslist absolute ...\n",
       "15795    forget make friend provide every hand dominant...\n",
       "Name: 1, Length: 59485, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c8906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_data = pd.DataFrame({'y': y_train, 'x':X_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e969a63d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENFP', 'INTP', 'ISFJ', 'INTJ', 'ENTP', 'INFJ', 'INFP', 'ENFJ',\n",
       "       'ENTJ', 'ISTP', 'ESTP', 'ISFP', 'ESFP', 'ISTJ', 'ESFJ', 'ESTJ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_data.iloc[:,0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a64004",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTP_table = sub_train_data[sub_train_data.iloc[:,0] == 'INTP'] # 1\n",
    "INFJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'INFJ'] # 2\n",
    "INTJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'INTJ'] # 3\n",
    "ENTJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'ENTJ'] # 4\n",
    "ENTP_table = sub_train_data[sub_train_data.iloc[:,0] == 'ENTP'] # 5\n",
    "INFP_table = sub_train_data[sub_train_data.iloc[:,0] == 'INFP'] # 6 \n",
    "ISTP_table = sub_train_data[sub_train_data.iloc[:,0] == 'ISTP'] # 7\n",
    "ISFJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'ISFJ'] # 8\n",
    "ENFP_table = sub_train_data[sub_train_data.iloc[:,0] == 'ENFP'] # 9\n",
    "ISFP_table = sub_train_data[sub_train_data.iloc[:,0] == 'ISFP'] # 10 \n",
    "ISTJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'ISTJ'] # 11\n",
    "ENFJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'ENFJ'] # 12\n",
    "ESTP_table = sub_train_data[sub_train_data.iloc[:,0] == 'ESTP'] # 13\n",
    "ESFP_table = sub_train_data[sub_train_data.iloc[:,0] == 'ESFP'] # 14\n",
    "ESTJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'ESTJ'] # 15\n",
    "ESFJ_table = sub_train_data[sub_train_data.iloc[:,0] == 'ESFJ'] # 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTP(1)\n",
    "print(INTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INTP_table.shape[0]):\n",
    "    text = INTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "intp = collections.Counter()\n",
    "for i in tmp:\n",
    "    intp += i\n",
    "    \n",
    "# save dataframe\n",
    "intp_df = pd.DataFrame.from_dict(intp, orient = 'index').reset_index()\n",
    "intp_df.to_csv('./sub_train_mbti_table/intp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4bac151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8533\n"
     ]
    }
   ],
   "source": [
    "# INFJ(2)\n",
    "print(INFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INFJ_table.shape[0]):\n",
    "    text = INFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "infj = collections.Counter()\n",
    "for i in tmp:\n",
    "    infj += i\n",
    "    \n",
    "# save dataframe\n",
    "infj_df = pd.DataFrame.from_dict(infj, orient = 'index').reset_index()\n",
    "infj_df.to_csv('./sub_train_mbti_table/infj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28453189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12854\n"
     ]
    }
   ],
   "source": [
    "# INTJ(3)\n",
    "print(INTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INTJ_table.shape[0]):\n",
    "    text = INTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "intj = collections.Counter()\n",
    "for i in tmp:\n",
    "    intj += i\n",
    "    \n",
    "# save dataframe\n",
    "intj_df = pd.DataFrame.from_dict(intj, orient = 'index').reset_index()\n",
    "intj_df.to_csv('./sub_train_mbti_table/intj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cd3542b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1676\n"
     ]
    }
   ],
   "source": [
    "# ENTJ(4)\n",
    "print(ENTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENTJ_table.shape[0]):\n",
    "    text = ENTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "entj = collections.Counter()\n",
    "for i in tmp:\n",
    "    entj += i\n",
    "    \n",
    "# save dataframe\n",
    "entj_df = pd.DataFrame.from_dict(entj, orient = 'index').reset_index()\n",
    "entj_df.to_csv('./sub_train_mbti_table/entj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dae23b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6721\n"
     ]
    }
   ],
   "source": [
    "# ENTP(5)\n",
    "print(ENTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENTP_table.shape[0]):\n",
    "    text = ENTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "entp = collections.Counter()\n",
    "for i in tmp:\n",
    "    entp += i\n",
    "    \n",
    "# save dataframe\n",
    "entp_df = pd.DataFrame.from_dict(entp, orient = 'index').reset_index()\n",
    "entp_df.to_csv('./sub_train_mbti_table/entp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a525e0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6724\n"
     ]
    }
   ],
   "source": [
    "# INFP(6)\n",
    "print(INFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, INFP_table.shape[0]):\n",
    "    text = INFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "infp = collections.Counter()\n",
    "for i in tmp:\n",
    "    infp += i\n",
    "    \n",
    "# save dataframe\n",
    "infp_df = pd.DataFrame.from_dict(infp, orient = 'index').reset_index()\n",
    "infp_df.to_csv('./sub_train_mbti_table/infp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea4175c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1929\n"
     ]
    }
   ],
   "source": [
    "# ISTP(7)\n",
    "print(ISTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISTP_table.shape[0]):\n",
    "    text = ISTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "istp = collections.Counter()\n",
    "for i in tmp:\n",
    "    istp += i\n",
    "    \n",
    "# save dataframe\n",
    "istp_df = pd.DataFrame.from_dict(istp, orient = 'index').reset_index()\n",
    "istp_df.to_csv('./sub_train_mbti_table/istp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d1ca205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n"
     ]
    }
   ],
   "source": [
    "# ISFJ(8)\n",
    "print(ISFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISFJ_table.shape[0]):\n",
    "    text = ISFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "isfj = collections.Counter()\n",
    "for i in tmp:\n",
    "    isfj += i\n",
    "    \n",
    "# save dataframe\n",
    "isfj_df = pd.DataFrame.from_dict(isfj, orient = 'index').reset_index()\n",
    "isfj_df.to_csv('./sub_train_mbti_table/isfj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52a2986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3510\n"
     ]
    }
   ],
   "source": [
    "# ENFP(9)\n",
    "print(ENFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENFP_table.shape[0]):\n",
    "    text = ENFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "enfp = collections.Counter()\n",
    "for i in tmp:\n",
    "    enfp += i\n",
    "    \n",
    "# save dataframe\n",
    "enfp_df = pd.DataFrame.from_dict(enfp, orient = 'index').reset_index()\n",
    "enfp_df.to_csv('./sub_train_mbti_table/enfp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93864879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481\n"
     ]
    }
   ],
   "source": [
    "# ISFP(10)\n",
    "print(ISFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISFP_table.shape[0]):\n",
    "    text = ISFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "isfp = collections.Counter()\n",
    "for i in tmp:\n",
    "    isfp += i\n",
    "    \n",
    "# save dataframe\n",
    "isfp_df = pd.DataFrame.from_dict(isfp, orient = 'index').reset_index()\n",
    "isfp_df.to_csv('./sub_train_mbti_table/isfp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d3e0857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n"
     ]
    }
   ],
   "source": [
    "# ISTJ(11)\n",
    "print(ISTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ISTJ_table.shape[0]):\n",
    "    text = ISTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "istj = collections.Counter()\n",
    "for i in tmp:\n",
    "    istj += i\n",
    "    \n",
    "# save dataframe\n",
    "istj_df = pd.DataFrame.from_dict(istj, orient = 'index').reset_index()\n",
    "istj_df.to_csv('./sub_train_mbti_table/istj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75575ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814\n"
     ]
    }
   ],
   "source": [
    "# ENFJ(12)\n",
    "print(ENFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ENFJ_table.shape[0]):\n",
    "    text = ENFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "enfj = collections.Counter()\n",
    "for i in tmp:\n",
    "    enfj += i\n",
    "    \n",
    "# save dataframe\n",
    "enfj_df = pd.DataFrame.from_dict(enfj, orient = 'index').reset_index()\n",
    "enfj_df.to_csv('./sub_train_mbti_table/enfj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "be719533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645\n"
     ]
    }
   ],
   "source": [
    "# ESTP(13)\n",
    "print(ESTP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESTP_table.shape[0]):\n",
    "    text = ESTP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "estp = collections.Counter()\n",
    "for i in tmp:\n",
    "    estp += i\n",
    "    \n",
    "# save dataframe\n",
    "estp_df = pd.DataFrame.from_dict(estp, orient = 'index').reset_index()\n",
    "estp_df.to_csv('./sub_train_mbti_table/estp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3ed6309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n"
     ]
    }
   ],
   "source": [
    "# ESFP(14)\n",
    "print(ESFP_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESFP_table.shape[0]):\n",
    "    text = ESFP_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "esfp = collections.Counter()\n",
    "for i in tmp:\n",
    "    esfp += i\n",
    "    \n",
    "# save dataframe\n",
    "esfp_df = pd.DataFrame.from_dict(esfp, orient = 'index').reset_index()\n",
    "esfp_df.to_csv('./sub_train_mbti_table/esfp_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeae88d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soon</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>something</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entp</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>struggle</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8180</th>\n",
       "      <td>doable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8181</th>\n",
       "      <td>snarky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8182</th>\n",
       "      <td>plaything</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8183</th>\n",
       "      <td>starve</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8184</th>\n",
       "      <td>stumble</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8185 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index    0\n",
       "0          soon   16\n",
       "1     something  315\n",
       "2          entp  102\n",
       "3          make  594\n",
       "4      struggle   16\n",
       "...         ...  ...\n",
       "8180     doable    1\n",
       "8181     snarky    1\n",
       "8182  plaything    1\n",
       "8183     starve    1\n",
       "8184    stumble    1\n",
       "\n",
       "[8185 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esfp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7695810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "# ESTJ(15)\n",
    "print(ESTJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESTJ_table.shape[0]):\n",
    "    text = ESTJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "estj = collections.Counter()\n",
    "for i in tmp:\n",
    "    estj += i\n",
    "    \n",
    "# save dataframe\n",
    "estj_df = pd.DataFrame.from_dict(estj, orient = 'index').reset_index()\n",
    "estj_df.to_csv('./sub_train_mbti_table/estj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce71d9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "# ESFJ(16)\n",
    "print(ESFJ_table.shape[0])\n",
    "\n",
    "# text split\n",
    "tmp = []\n",
    "for i in range(0, ESFJ_table.shape[0]):\n",
    "    text = ESFJ_table.iloc[i,1]\n",
    "    tmp_list = text.split(\" \")\n",
    "    tmp.append(collections.Counter(tmp_list))\n",
    "\n",
    "# word count\n",
    "esfj = collections.Counter()\n",
    "for i in tmp:\n",
    "    esfj += i\n",
    "    \n",
    "# save dataframe\n",
    "esfj_df = pd.DataFrame.from_dict(esfj, orient = 'index').reset_index()\n",
    "esfj_df.to_csv('./sub_train_mbti_table/esfj_df.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc9214e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intp_df = pd.read_csv('./sub_train_mbti_table/intp_df.csv') # 1\n",
    "infj_df = pd.read_csv('./sub_train_mbti_table/infj_df.csv') # 2\n",
    "intj_df = pd.read_csv('./sub_train_mbti_table/intj_df.csv') # 3\n",
    "entj_df = pd.read_csv('./sub_train_mbti_table/entj_df.csv') # 4\n",
    "entp_df = pd.read_csv('./sub_train_mbti_table/entp_df.csv') # 5\n",
    "infp_df = pd.read_csv('./sub_train_mbti_table/infp_df.csv') # 6\n",
    "istp_df = pd.read_csv('./sub_train_mbti_table/istp_df.csv') # 7\n",
    "isfj_df = pd.read_csv('./sub_train_mbti_table/isfj_df.csv') # 8\n",
    "enfp_df = pd.read_csv('./sub_train_mbti_table/enfp_df.csv') # 9\n",
    "isfp_df = pd.read_csv('./sub_train_mbti_table/isfp_df.csv') # 10\n",
    "istj_df = pd.read_csv('./sub_train_mbti_table/istj_df.csv') # 11\n",
    "enfj_df = pd.read_csv('./sub_train_mbti_table/enfj_df.csv') # 12\n",
    "estp_df = pd.read_csv('./sub_train_mbti_table/estp_df.csv') # 13\n",
    "esfp_df = pd.read_csv('./sub_train_mbti_table/esfp_df.csv') # 14\n",
    "estj_df = pd.read_csv('./sub_train_mbti_table/estj_df.csv') # 15\n",
    "esfj_df = pd.read_csv('./sub_train_mbti_table/esfj_df.csv') # 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dfb730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2301314a",
   "metadata": {},
   "source": [
    "**sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339ce903",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_list = ['intp', 'infj', 'intj', 'entj', 'entp', 'infp', 'istp', 'isfj',\n",
    "             'enfp', 'isfp', 'istj', 'enfj', 'estp', 'esfp', 'estj', 'esfj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a98e6f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mbti_preq = pd.DataFrame(sub_train_data.iloc[:,0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cebda328",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1cad2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7098\n",
      "7098\n"
     ]
    }
   ],
   "source": [
    "# intp (1)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = intp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INTP'].item()/ratio) * 400\n",
    "\n",
    "sample = intp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) + \" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "intp_new_data = pd.DataFrame({'y':'INTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9901c3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4266\n",
      "4266\n"
     ]
    }
   ],
   "source": [
    "# infj (2)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = infj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = infj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "infj_new_data = pd.DataFrame({'y':'INFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dca3be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6427\n",
      "6427\n"
     ]
    }
   ],
   "source": [
    "# intj (3)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = intj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = intj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "intj_new_data = pd.DataFrame({'y':'INTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "438ad7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\n",
      "838\n"
     ]
    }
   ],
   "source": [
    "# entj (4)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = entj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = entj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "entj_new_data = pd.DataFrame({'y':'ENTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe4d7ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3360\n",
      "3360\n"
     ]
    }
   ],
   "source": [
    "# entp (5)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = entp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENTP'].item()/ratio) * 400\n",
    "\n",
    "sample = entp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "entp_new_data = pd.DataFrame({'y':'ENTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0bd9769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3362\n",
      "3362\n"
     ]
    }
   ],
   "source": [
    "# infp (6)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = infp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['INFP'].item()/ratio) * 400\n",
    "\n",
    "sample = infp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['INFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "infp_new_data = pd.DataFrame({'y':'INFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e71774d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964\n",
      "964\n"
     ]
    }
   ],
   "source": [
    "# istp (7)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = istp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISTP'].item()/ratio) * 400\n",
    "\n",
    "sample = istp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "istp_new_data = pd.DataFrame({'y':'ISTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c4fb55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "# isfj (8)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = isfj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = isfj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "isfj_new_data = pd.DataFrame({'y':'ISFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85f82987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755\n",
      "1755\n"
     ]
    }
   ],
   "source": [
    "# enfp (9)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = enfp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENFP'].item()/ratio) * 400\n",
    "\n",
    "sample = enfp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "enfp_new_data = pd.DataFrame({'y':'ENFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71ef2e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "# isfp (10)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = isfp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISFP'].item()/ratio) * 400\n",
    "\n",
    "sample = isfp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "isfp_new_data = pd.DataFrame({'y':'ISFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f7c28dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "# istj (11)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = istj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ISTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = istj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ISTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "istj_new_data = pd.DataFrame({'y':'ISTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5b0f7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407\n",
      "407\n"
     ]
    }
   ],
   "source": [
    "# enfj (12)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = enfj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ENFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = enfj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ENFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "enfj_new_data = pd.DataFrame({'y':'ENFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10deec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "# estp (13)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = estp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESTP'].item()/ratio) * 400\n",
    "\n",
    "sample = estp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESTP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "estp_new_data = pd.DataFrame({'y':'ESTP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6ab8e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# esfp (14)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = esfp_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESFP'].item()/ratio) * 400\n",
    "\n",
    "sample = esfp_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESFP'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "esfp_new_data = pd.DataFrame({'y':'ESFP', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a6ebca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>sound management intps however time time littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>person band friend whenever think nt thank mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>hate time hard bullshit stereotype opposite fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>confuse go e think remind recommend start sinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>would think fuck say u introvert idea wavelenh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>everyone uncharacteristic talk ne next awkward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>take light good location downvoted negative co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>disc power ideal throne well put say trust lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>achiever degree big ask change every type men ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>esfps relate silly like thing hear life inform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y                                                  x\n",
       "0   ESFP  sound management intps however time time littl...\n",
       "1   ESFP  person band friend whenever think nt thank mak...\n",
       "2   ESFP  hate time hard bullshit stereotype opposite fr...\n",
       "3   ESFP  confuse go e think remind recommend start sinc...\n",
       "4   ESFP  would think fuck say u introvert idea wavelenh...\n",
       "..   ...                                                ...\n",
       "95  ESFP  everyone uncharacteristic talk ne next awkward...\n",
       "96  ESFP  take light good location downvoted negative co...\n",
       "97  ESFP  disc power ideal throne well put say trust lik...\n",
       "98  ESFP  achiever degree big ask change every type men ...\n",
       "99  ESFP  esfps relate silly like thing hear life inform...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esfp_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dc13b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# estj (15)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = estj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESTJ'].item()/ratio) * 400\n",
    "\n",
    "sample = estj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESTJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "estj_new_data = pd.DataFrame({'y':'ESTJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc924589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# esfj (16)\n",
    "\n",
    "# 단어 샘플링\n",
    "tmp_preq = esfj_df.iloc[:,1] \n",
    "sample_num = int(mbti_preq.loc['ESFJ'].item()/ratio) * 400\n",
    "\n",
    "sample = esfj_df['index'].sample(n = sample_num, replace = True, random_state = 42, weights = tmp_preq)\n",
    "\n",
    "# 문장 만들기\n",
    "post = []\n",
    "sentence = \"\"\n",
    "for i in range(0,len(sample)):\n",
    "    sentence += (str(sample.iloc[i]) +\" \")\n",
    "    if (i+1)%400 == 0:\n",
    "        #print(i)\n",
    "        post.append(sentence)\n",
    "        sentence = \"\"\n",
    "        \n",
    "print(int(mbti_preq.loc['ESFJ'].item()/ratio))\n",
    "print(len(post))\n",
    "\n",
    "# 데이터프레임으로 만들기\n",
    "esfj_new_data = pd.DataFrame({'y':'ESFJ', 'x':post})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3061f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = pd.concat([intp_new_data, infj_new_data, intj_new_data, entj_new_data,\n",
    "                            entp_new_data, infp_new_data, istp_new_data, isfj_new_data,\n",
    "                            enfp_new_data, isfp_new_data, istj_new_data, enfj_new_data,\n",
    "                            estp_new_data, esfp_new_data, estj_new_data, esfj_new_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ceb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2623e366",
   "metadata": {},
   "source": [
    "**modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfd0112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_accuracy(prediction, answer):\n",
    "    prediction_list = list(prediction)\n",
    "    answer_list = list(answer)\n",
    "    list_size = answer.size\n",
    "    \n",
    "    correct_num = 0\n",
    "    \n",
    "    for i in range(list_size):\n",
    "        for j in range(4):\n",
    "            if prediction_list[i][j] == answer_list[i][j] :\n",
    "                correct_num += 1;\n",
    "                \n",
    "    accuracy = correct_num / (4*list_size)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a518fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_data.columns = ['y', 'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c57b8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_new_train_data = pd.concat([sub_train_data, new_train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_new_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a41e1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = total_new_train_data.iloc[:,1] # features\n",
    "new_y = total_new_train_data.iloc[:,0]  # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925bed5",
   "metadata": {},
   "source": [
    "**new_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "486afa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#vectorizer = TfidfVectorizer(min_df = 4, sublinear_tf = True, ngram_range = (1, 2))\n",
    "vectorizer = TfidfVectorizer()\n",
    "   \n",
    "# Training the vectorizer:\n",
    "X_train_tfidf = vectorizer.fit_transform(new_X)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7799b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013038b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb48657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d1b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e40c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185094f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4232d766",
   "metadata": {},
   "source": [
    "**LinearSVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96e54525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "new_model = LinearSVC()\n",
    "new_model.fit(X_train_tfidf, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c9e20d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = new_model.predict(X_train_tfidf)\n",
    "valid_predict = new_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adea75f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 후 훈련데이터 전체 단위 정확도:  0.9850824890164082\n",
      "데이터 증폭 후 검증데이터 전체 단위 정확도:  0.7947821409359871\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 후 훈련데이터 전체 단위 정확도: ', np.mean(train_predict == new_y))\n",
    "print('데이터 증폭 후 검증데이터 전체 단위 정확도: ', np.mean(valid_predict == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7644ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 후 훈련데이터 글자별 정확도:  0.9945502331211333\n",
      "데이터 증폭 후 검증데이터 글자별 정확도:  0.9213791016675632\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 후 훈련데이터 글자별 정확도: ', caculate_accuracy(train_predict, new_y))\n",
    "print('데이터 증폭 후 검증데이터 글자별 정확도: ', caculate_accuracy(valid_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c32506a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>585</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>305</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>1270</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>26</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1816</td>\n",
       "      <td>119</td>\n",
       "      <td>92</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1345</td>\n",
       "      <td>43</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>2695</td>\n",
       "      <td>265</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "      <td>285</td>\n",
       "      <td>2979</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2     3   4   5   6    7     8     9     10    11  12  13   14  \\\n",
       "0   119    1    0     2   1   0   1    1     5     7     2     1   2   1    2   \n",
       "1     8  585    9    22   2   4   0    0    41    37    23    15   3   0    6   \n",
       "2     4    3  305     5   1   0   3    0     3     4    12     4   0   1    1   \n",
       "3     6   23   11  1270   3   8   1    6    53    26    51    65   4   8    4   \n",
       "4     0    0    0     0   9   0   0    0     0     1     0     0   0   0    1   \n",
       "5     0    1    0     2   1  24   0    0     0     0     0     1   0   2    0   \n",
       "6     0    0    0     0   0   0   0    0     0     0     0     0   0   0    0   \n",
       "7     0    1    0     1   0   0   0  132     5     2     2     5   0   0    1   \n",
       "8    32   64   17    45   4   2   1    2  1816   119    92    51   9   9   13   \n",
       "9    13   67    4    24   0   3   3    0   111  1345    43    75  13  30   16   \n",
       "10    7   62   55    69   2   6   0    8    96    59  2695   265   8   7   30   \n",
       "11   19   17   25   130   2   3   0   17    87   105   285  2979   6  11   16   \n",
       "12    1    1    2     1   2   0   2    0     3     4     2     1  45   1    2   \n",
       "13    1    0    0     2   0   1   0    0     7     2     1     2   2  66    1   \n",
       "14    0    2    1     2   0   0   0    0     3     3     3     6   0   1  100   \n",
       "15    0    1    1     7   0   0   0    3     2     6    14    23   0   2    5   \n",
       "\n",
       "     15  \n",
       "0     2  \n",
       "1     9  \n",
       "2     2  \n",
       "3    18  \n",
       "4     0  \n",
       "5     1  \n",
       "6     0  \n",
       "7     0  \n",
       "8     9  \n",
       "9    11  \n",
       "10   29  \n",
       "11   52  \n",
       "12    0  \n",
       "13    0  \n",
       "14    2  \n",
       "15  330  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(valid_predict, y_test)) # 행이 예측, 열이 실제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7d19a",
   "metadata": {},
   "source": [
    "**LinearSVC(penalty = 'l1')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0700974",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_l1_model = LinearSVC(penalty='l1', C = 1, dual = False, random_state = 42)\n",
    "svc_l1_model.fit(X_train_tfidf, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e351c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_l1_train_predict = svc_l1_model.predict(X_train_tfidf)\n",
    "svc_l1_valid_predict = svc_l1_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 증폭 후 훈련데이터 전체 단위 정확도: ', np.mean(svc_l1_train_predict == new_y))\n",
    "print('데이터 증폭 후 검증데이터 전체 단위 정확도: ', np.mean(svc_l1_valid_predict == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99fdd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 증폭 후 훈련데이터 글자별 정확도: ', caculate_accuracy(svc_l1_train_predict, new_y))\n",
    "print('데이터 증폭 후 검증데이터 글자별 정확도: ', caculate_accuracy(svc_l1_valid_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(tree_valid_predict, y_test)) # 행이 예측, 열이 실제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1d809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84825c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c64c58ce",
   "metadata": {},
   "source": [
    "**LinearSVC(정규화)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbf241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6b383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d8c2ce1",
   "metadata": {},
   "source": [
    "**linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69a8e14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_tfidf, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be1f342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_train_predict = logistic_model.predict(X_train_tfidf)\n",
    "logistic_valid_predict = logistic_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17a980c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 후 훈련데이터 전체 단위 정확도:  0.8978862189545413\n",
      "데이터 증폭 후 검증데이터 전체 단위 정확도:  0.7875874125874126\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 후 훈련데이터 전체 단위 정확도: ', np.mean(logistic_train_predict == new_y))\n",
    "print('데이터 증폭 후 검증데이터 전체 단위 정확도: ', np.mean(logistic_valid_predict == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b70bd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 후 훈련데이터 글자별 정확도:  0.9600976194745808\n",
      "데이터 증폭 후 검증데이터 글자별 정확도:  0.918185180204411\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 후 훈련데이터 글자별 정확도: ', caculate_accuracy(logistic_train_predict, new_y))\n",
    "print('데이터 증폭 후 검증데이터 글자별 정확도: ', caculate_accuracy(logistic_valid_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d559e0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>585</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>305</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>1270</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>26</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1816</td>\n",
       "      <td>119</td>\n",
       "      <td>92</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1345</td>\n",
       "      <td>43</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>2695</td>\n",
       "      <td>265</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>87</td>\n",
       "      <td>105</td>\n",
       "      <td>285</td>\n",
       "      <td>2979</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2     3   4   5   6    7     8     9     10    11  12  13   14  \\\n",
       "0   119    1    0     2   1   0   1    1     5     7     2     1   2   1    2   \n",
       "1     8  585    9    22   2   4   0    0    41    37    23    15   3   0    6   \n",
       "2     4    3  305     5   1   0   3    0     3     4    12     4   0   1    1   \n",
       "3     6   23   11  1270   3   8   1    6    53    26    51    65   4   8    4   \n",
       "4     0    0    0     0   9   0   0    0     0     1     0     0   0   0    1   \n",
       "5     0    1    0     2   1  24   0    0     0     0     0     1   0   2    0   \n",
       "6     0    0    0     0   0   0   0    0     0     0     0     0   0   0    0   \n",
       "7     0    1    0     1   0   0   0  132     5     2     2     5   0   0    1   \n",
       "8    32   64   17    45   4   2   1    2  1816   119    92    51   9   9   13   \n",
       "9    13   67    4    24   0   3   3    0   111  1345    43    75  13  30   16   \n",
       "10    7   62   55    69   2   6   0    8    96    59  2695   265   8   7   30   \n",
       "11   19   17   25   130   2   3   0   17    87   105   285  2979   6  11   16   \n",
       "12    1    1    2     1   2   0   2    0     3     4     2     1  45   1    2   \n",
       "13    1    0    0     2   0   1   0    0     7     2     1     2   2  66    1   \n",
       "14    0    2    1     2   0   0   0    0     3     3     3     6   0   1  100   \n",
       "15    0    1    1     7   0   0   0    3     2     6    14    23   0   2    5   \n",
       "\n",
       "     15  \n",
       "0     2  \n",
       "1     9  \n",
       "2     2  \n",
       "3    18  \n",
       "4     0  \n",
       "5     1  \n",
       "6     0  \n",
       "7     0  \n",
       "8     9  \n",
       "9    11  \n",
       "10   29  \n",
       "11   52  \n",
       "12    0  \n",
       "13    0  \n",
       "14    2  \n",
       "15  330  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(valid_predict, y_test)) # 행이 예측, 열이 실제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f98a8a",
   "metadata": {},
   "source": [
    "**Decision_tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f485a33f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      2\u001b[0m tree_model \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtree_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train_tfidf, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_train_predict = tree_model.predict(X_train_tfidf)\n",
    "tree_valid_predict = tree_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48dae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 증폭 후 훈련데이터 전체 단위 정확도: ', np.mean(tree_train_predict == new_y))\n",
    "print('데이터 증폭 후 검증데이터 전체 단위 정확도: ', np.mean(tree_valid_predict == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8148aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 증폭 후 훈련데이터 글자별 정확도: ', caculate_accuracy(tree_train_predict, new_y))\n",
    "print('데이터 증폭 후 검증데이터 글자별 정확도: ', caculate_accuracy(tree_valid_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(tree_valid_predict, y_test)) # 행이 예측, 열이 실제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58857523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b572d82",
   "metadata": {},
   "source": [
    "**deep learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef0d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding\n",
    "from keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848988c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 1000) # 가장 빈도가 높은 1000개의 단어 \n",
    "tokenizer.fit_on_texts(new_X) # 단어 인덱스 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(new_X) # 문자열을 정수 인덱스의 리스트로 변환\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 3000\n",
    "\n",
    "X_train = preprocessing.sequence.pad_sequences(train_sequences, maxlen = maxlen)\n",
    "X_test = preprocessing.sequence.pad_sequences(test_sequences, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54445a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_for_deep = new_y.replace({'INTP':0, 'INFJ':1, 'INTJ':2, 'ENTJ':3, 'ENTP':4, 'INFP':5,\n",
    "                 'ISTP':6, 'ISFJ':7, 'ENFP':8, 'ISFP':9, 'ISTJ':10, 'ENFJ':11,\n",
    "                 'ESTP':12, 'ESFP':13, 'ESTJ':14, 'ESFJ':15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5780e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension = 16):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "new_y_for_deep_onehot = to_one_hot(new_y_for_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0fc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "final_model = Sequential()\n",
    "final_model.add(Embedding(1000, 8, input_length = maxlen))\n",
    "\n",
    "final_model.add(Flatten()) # (samples, maxlen * 8) 크기의 2D 텐서로 펼친다.\n",
    "\n",
    "final_model.add(Dense(16, activation = 'sigmoid'))\n",
    "final_model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d362801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = final_model.fit(X_train, y_train_label, epochs =4, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5193fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 그래프 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e6241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137181a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89974981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed9d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615c182e",
   "metadata": {},
   "source": [
    "**randomforest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa28ec68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=100, random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(min_samples_split = 1000, n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c02a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = rf_model.predict(X_train_tfidf)\n",
    "valid_predict = rf_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4becd993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 후 훈련데이터 전체 단위 정확도:  0.7893616067425805\n",
      "데이터 증폭 후 검증데이터 전체 단위 정확도:  0.486013986013986\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 후 훈련데이터 전체 단위 정확도: ', np.mean(train_predict == new_y))\n",
    "print('데이터 증폭 후 검증데이터 전체 단위 정확도: ', np.mean(valid_predict == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35da6bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 후 훈련데이터 글자별 정확도:  0.9079451717026809\n",
      "데이터 증폭 후 검증데이터 글자별 정확도:  0.8045992469069392\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 후 훈련데이터 글자별 정확도: ', caculate_accuracy(train_predict, new_y))\n",
    "print('데이터 증폭 후 검증데이터 글자별 정확도: ', caculate_accuracy(valid_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01e4f0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>216</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1033</td>\n",
       "      <td>300</td>\n",
       "      <td>151</td>\n",
       "      <td>131</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>440</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43</td>\n",
       "      <td>288</td>\n",
       "      <td>132</td>\n",
       "      <td>183</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>405</td>\n",
       "      <td>228</td>\n",
       "      <td>2211</td>\n",
       "      <td>225</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>60</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>115</td>\n",
       "      <td>277</td>\n",
       "      <td>213</td>\n",
       "      <td>1010</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>107</td>\n",
       "      <td>746</td>\n",
       "      <td>746</td>\n",
       "      <td>853</td>\n",
       "      <td>3128</td>\n",
       "      <td>55</td>\n",
       "      <td>77</td>\n",
       "      <td>107</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2     3   4   5   6    7     8    9     10    11  12  13   14  \\\n",
       "0     0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "1     0    2    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "2     0    0   62     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "3     5   17    7   312   2   4   0    0    16    6     7     3   2   6    4   \n",
       "4     0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "5     0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "6     0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "7     0    0    0     0   0   0   0   32     0    0     0     0   0   0    0   \n",
       "8    43  216   14    73   6  10   0    2  1033  300   151   131  12  27   23   \n",
       "9     4   28    2     4   2   1   1    1    32  440     3     6   1  11    4   \n",
       "10   43  288  132   183   6  13   2   27   405  228  2211   225  22  18   60   \n",
       "11  115  277  213  1010  11  23   8  107   746  746   853  3128  55  77  107   \n",
       "12    0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "13    0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "14    0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "15    0    0    0     0   0   0   0    0     0    0     0     0   0   0    0   \n",
       "\n",
       "     15  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     2  \n",
       "4     0  \n",
       "5     0  \n",
       "6     0  \n",
       "7     0  \n",
       "8    21  \n",
       "9     0  \n",
       "10   72  \n",
       "11  362  \n",
       "12    0  \n",
       "13    0  \n",
       "14    0  \n",
       "15    8  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(valid_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21843118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb3854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9952567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6537789a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60713f2a",
   "metadata": {},
   "source": [
    "**origin_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ff097688",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "   \n",
    "# Training the vectorizer:\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9ba2b42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "origin_model = LinearSVC()\n",
    "origin_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "db1b88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict = origin_model.predict(X_train_tfidf)\n",
    "valid_predict = origin_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "95810a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 전 훈련데이터 전체 단위 정확도:  0.9804152307304362\n",
      "데이터 증폭 전 검증데이터 전체 단위 정확도:  0.7893356643356644\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 전 훈련데이터 전체 단위 정확도: ', np.mean(train_predict == y_train))\n",
    "print('데이터 증폭 전 검증데이터 전체 단위 정확도: ', np.mean(valid_predict == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8d13ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 증폭 전 훈련데이터 글자별 정확도:  0.992804908800538\n",
      "데이터 증폭 전 검증데이터 글자별 정확도:  0.9193450779989242\n"
     ]
    }
   ],
   "source": [
    "print('데이터 증폭 전 훈련데이터 글자별 정확도: ', caculate_accuracy(train_predict, y_train))\n",
    "print('데이터 증폭 전 검증데이터 글자별 정확도: ', caculate_accuracy(valid_predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea60df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
